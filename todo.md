### Week of 2020-03-22 - 2020-03-28
- setup.py (scrapy cloud)
    - https://medium.com/@chiayinchen/crawler-what-can-i-do-with-scrapy-cloud-edc336bc85e7
    .
    ├── CarolCrawler
    │   ├── __init__.py
    │   ├── items.py
    │   ├── middlewares.py
    │   ├── pipelines.py
    │   ├── settings.py
    │   └── spiders
    │       ├── __init__.py
    │       └── QuotesSpider.py
    ├── bin
    │   └── Hello.py
    │   └── Hello2Crawler.py
    ├── scrapinghub.yml
    ├── scrapy.cfg
    └── setup.py

### Week of 2020-03-08 - 2020-03-14

- scraping amazon.com product data (price history)
    web scraping platform
- update amazonmws with a modern python3, angular, and docker
    scrape amazon.com products
- Technical Stack
    database - MySQL 8.x/Django 3.0.*
    backend - python 3.7.x/Scrapy 2.0.x/Flask 1.1.x
    frontend - Angular 1.7.x
- Docker based applications

## Mar 12 2020
- django migration
- init scrapy

## Mar 13 2020
- checkout distributed crawls
    https://docs.scrapy.org/en/latest/topics/practices.html#distributed-crawls
- You can access the cached version for any page that has been saved by Google with this:
    https://webapps.stackexchange.com/a/22111

## Mar 16 2020
- scrapyd
    https://github.com/scrapy/scrapyd-client
    https://scrapyd.readthedocs.io/en/latest/overview.html#how-scrapyd-works
- scrapydweb
    https://github.com/my8100/scrapydweb

